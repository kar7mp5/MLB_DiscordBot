{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.llms import Ollama\n",
    "from langchain import PromptTemplate\n",
    "import wikipedia\n",
    "from langchain.docstore.document import Document\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain.chains import RetrievalQA\n",
    "from langchain.vectorstores import Chroma\n",
    "from langchain.embeddings import SentenceTransformerEmbeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_keyword(model, user_prompt):\n",
    "    \"\"\"Extract keyword from user prompt using LLM model\"\"\"\n",
    "\n",
    "    keyword_extract_system_prompt = \"\"\"\n",
    "Think and write your step-by-step reasoning before responding.\n",
    "Please write only the fully spelled-out form of the acronym in English that corresponds to the following user's question, without abbreviations or additional text.\n",
    "If you don't know how to respond, just say false.\n",
    "\"\"\"\n",
    "    \n",
    "    template = \"\"\"\n",
    "<|begin_of_text|>\n",
    "<|start_header_id|>system<|end_header_id|>\n",
    "{system_prompt}\n",
    "<|eot_id|>\n",
    "<|start_header_id|>user<|end_header_id|>\n",
    "{user_prompt}\n",
    "<|eot_id|>\n",
    "<|start_header_id|>assistant<|end_header_id|>\n",
    "\"\"\"\n",
    "    \n",
    "    prompt = PromptTemplate(input_variables=['system_prompt', 'user_prompt'], template=template)\n",
    "    keyword = model(prompt.format(system_prompt=keyword_extract_system_prompt, user_prompt=user_prompt)).strip()\n",
    "    \n",
    "    return keyword\n",
    "\n",
    "\n",
    "def get_wikipedia_content(keyword):\n",
    "    \"\"\"Fetch content from Wikipedia based on the keyword\"\"\"\n",
    "    try:\n",
    "        search_results = wikipedia.search(keyword)\n",
    "        if not search_results:\n",
    "            return None\n",
    "        page_content = wikipedia.page(search_results[0]).content\n",
    "        return page_content\n",
    "    except Exception as e:\n",
    "        print(f\"Error fetching Wikipedia content: {e}\")\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_response(model, user_prompt, content=None):\n",
    "    \"\"\"Generate response using GPT model with optional document content\"\"\"\n",
    "\n",
    "    system_prompt = \"\"\"\n",
    "Please write all conversations in Korean(한국어).\n",
    "Think and write your step-by-step reasoning before responding.\n",
    "Write the article title using ## in Markdown syntax.\n",
    "\"\"\"\n",
    "    \n",
    "    template = \"\"\"\n",
    "<|begin_of_text|>\n",
    "<|start_header_id|>system<|end_header_id|>\n",
    "{system_prompt}\n",
    "<|eot_id|>\n",
    "<|start_header_id|>user<|end_header_id|>\n",
    "{user_prompt}\n",
    "<|eot_id|>\n",
    "<|start_header_id|>assistant<|end_header_id|>\n",
    "\"\"\"\n",
    "    \n",
    "    prompt = PromptTemplate(input_variables=['system_prompt', 'user_prompt'], template=template)\n",
    "    if content:\n",
    "        # Split and embed content if provided\n",
    "        doc = Document(page_content=content)\n",
    "        text_splitter = RecursiveCharacterTextSplitter(chunk_size=500, chunk_overlap=0)\n",
    "        all_splits = text_splitter.split_documents([doc])\n",
    "        embeddings = SentenceTransformerEmbeddings(model_name=\"all-MiniLM-L6-v2\")\n",
    "        vectorstore = Chroma.from_documents(documents=all_splits, embedding=embeddings)\n",
    "        \n",
    "        # Use RAG for response generation\n",
    "        qachain = RetrievalQA.from_chain_type(model, retriever=vectorstore.as_retriever())\n",
    "        response = qachain(prompt.format(system_prompt=system_prompt, user_prompt=user_prompt))\n",
    "        return response['result']\n",
    "    else:\n",
    "        # Generate response without additional document\n",
    "        response = model(prompt.format(system_prompt=system_prompt, user_prompt=user_prompt)).strip()\n",
    "        return response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/kar/Projects/MLB_DiscordBot/venv/lib/python3.10/site-packages/wikipedia/wikipedia.py:389: GuessedAtParserWarning: No parser was explicitly specified, so I'm using the best available HTML parser for this system (\"html.parser\"). This usually isn't a problem, but if you run this code on another system, or in a different virtual environment, it may use a different parser and behave differently.\n",
      "\n",
      "The code that caused this warning is on line 389 of the file /home/kar/Projects/MLB_DiscordBot/venv/lib/python3.10/site-packages/wikipedia/wikipedia.py. To get rid of this warning, pass the additional argument 'features=\"html.parser\"' to the BeautifulSoup constructor.\n",
      "\n",
      "  lis = BeautifulSoup(html).find_all('li')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error fetching Wikipedia content: \"Python\" may refer to: \n",
      "Pythonidae\n",
      "Python (genus)\n",
      "Python (mythology)\n",
      "Python (programming language)\n",
      "CMU Common Lisp\n",
      "PERQ 3\n",
      "Python of Aenus\n",
      "Python (painter)\n",
      "Python of Byzantium\n",
      "Python of Catana\n",
      "Python Anghelo\n",
      "Python (Efteling)\n",
      "Python (Busch Gardens Tampa Bay)\n",
      "Python (Coney Island, Cincinnati, Ohio)\n",
      "Python (automobile maker)\n",
      "Python (Ford prototype)\n",
      "Python (missile)\n",
      "Python (nuclear primary)\n",
      "Colt Python\n",
      "Python (codename)\n",
      "Python (film)\n",
      "Monty Python\n",
      "Python (Monty) Pictures\n",
      "Timon of Phlius\n",
      "Pithon\n",
      "Pyton\n",
      "문서를 찾을 수 없습니다. 검색 없이 응답을 생성합니다.\n",
      "응답: ## Python 설명\n",
      "\n",
      "Python은 **versatile**하고 **easy to learn**의 프로그래밍 언어입니다. 🐍  대규모 데이터셋을 분석하기, 웹 애플리케이션 개발하기, 머신러닝 알고리즘 구현 등 다양한 분야에서 사용됩니다. 특히 Python이 **반복적인 작업**이나 **데이터 처리**에 효과적이기 때문에 많은 프로그래밍자가 선택합니다. \n",
      "\n",
      "### Python의 장점\n",
      "\n",
      "* **편리한 설치 및 활용:** Python은 간단하게 다운로드하고 설치하여 사용할 수 있습니다.  \n",
      "* **활발한 커뮤니티 & 풍부한 도구:** Python은 대규모 커뮤니티와 다양한 라이브러리를 지원하는 강력한 지원망을 제공합니다. \n",
      "\n",
      "**Python의 활용 예시:**\n",
      "\n",
      "* **데이터 분석:** 데이터 시각화, 통계 및 머신러닝 알고리즘을 사용하여 데이터를 분석하고 이해할 수 있습니다.\n",
      "* **웹 애플리케이션 개발:** Python은 웹 서버를 구축하기 위해 사용될 수 있는 다양한 라이브러리를 지원합니다. \n",
      "* **머신 러닝:**  Python은 머신 러닝 모델을 개발하는 데 매우 적합하며 다양한 AI 기술들을 실제로 활용할 수 있습니다.\n",
      "\n",
      "**결론적으로 Python은 단순하고 유연하면서도 강력함을 동시에 제공하는 프로그래밍 언어입니다.** 🚀\n"
     ]
    }
   ],
   "source": [
    "def main():\n",
    "    model = Ollama(model='gemma2:2b', stop=[\"<|eot_id|>\"])\n",
    "    \n",
    "    user_input = input(\"질문을 입력하세요: \")\n",
    "    keyword = extract_keyword(model, user_input)\n",
    "\n",
    "    if keyword == \"false\":\n",
    "        print(\"키워드를 찾을 수 없습니다. 검색 없이 응답을 생성합니다.\")\n",
    "        response = generate_response(model, user_input)\n",
    "    else:\n",
    "        content = get_wikipedia_content(keyword)\n",
    "        if content:\n",
    "            print(f\"{keyword}에 대한 Wikipedia 문서를 찾았습니다.\")\n",
    "            response = generate_response(model, user_input, content=content)\n",
    "        else:\n",
    "            print(\"문서를 찾을 수 없습니다. 검색 없이 응답을 생성합니다.\")\n",
    "            response = generate_response(model, user_input)\n",
    "    \n",
    "    print(\"응답:\", response)\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
